{
  "permissions": {
    "allow": [
      "WebFetch(domain:github.com)",
      "WebFetch(domain:deno.land)",
      "Bash(test:*)",
      "Bash(npx supabase:*)",
      "Bash(npm search:*)",
      "WebFetch(domain:registry.modelcontextprotocol.io)",
      "Bash(pip install:*)",
      "Bash(npx -y @smithery/cli install:*)",
      "Bash(npx:*)",
      "Bash(node --version:*)",
      "Bash(git clone:*)",
      "Bash(npm install)",
      "Bash(npm run build:*)",
      "Bash(echo:*)",
      "Bash(powershell -c \"irm bun.sh/install.ps1 | iex\")",
      "Bash(export PATH=\"$PATH:/c/Users/User/.bun/bin\")",
      "Bash(bun:*)",
      "Bash(bun run build)",
      "Bash(~/supabase-mcp/dist/index.js --help)",
      "Bash(git diff:*)",
      "mcp__supabase__execute_sql",
      "Bash(git add:*)",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nfix: prevent verbatim user notes from being injected into QA retry prompts\n\nProblem: User rejection notes were being copied verbatim into retry\ngeneration prompts, causing prompt pollution and inconsistent behavior.\n\nSolution: Convert all user feedback to structured patterns/categories.\n\nChanges:\n- analyze-rejection: Extract rejection patterns, not verbatim text\n- optimize-pipeline-prompt: Use sentiment analysis instead of raw comments\n- human-feedback-memory: Show pattern tags [extra_furniture, camera_mismatch]\n  instead of verbatim quotes\n\nFiles modified:\n- supabase/functions/analyze-rejection/index.ts\n- supabase/functions/optimize-pipeline-prompt/index.ts\n- supabase/functions/_shared/human-feedback-memory.ts\n- docs/QA_FEEDBACK_FIX_SUMMARY.md \\(new\\)\n- docs/QA_FEEDBACK_FIX_DELIVERABLES.md \\(new\\)\n\nTesting: User note \"\"Too much clutter\"\" now becomes pattern [extra_furniture,\nminimalism_preference] in retry prompts, not verbatim text.\n\nCo-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nfeat: add comprehensive Langfuse tracing diagnostics\n\nAdded diagnostic logging to identify why Langfuse traces aren''t appearing.\nAll changes are temporary and non-blocking - pipeline continues if Langfuse fails.\n\nChanges:\n- langfuse-client.ts: Added diagnostic logs for config, trace, generation, and flush\n- run-space-analysis.ts: Added connectivity test and trace creation diagnostics\n- verify-langfuse-config \\(new\\): Dedicated endpoint to check Langfuse configuration\n- LANGFUSE_DIAGNOSTIC_GUIDE.md \\(new\\): Complete diagnostic and troubleshooting guide\n- LANGFUSE_RESTORE_SUMMARY.md \\(new\\): Implementation summary and action items\n\nDiagnostic logs show:\n- Environment variable status \\(safe - no secrets logged\\)\n- Connectivity test results\n- Trace/generation creation status\n- Event queue and flush operations\n- HTTP response codes from Langfuse API\n\nNext steps:\n1. Run: npx supabase functions invoke verify-langfuse-config\n2. Check run-space-analysis logs for [LANGFUSE_DIAGNOSTIC] entries\n3. Fix any identified issues \\(env vars, connectivity, etc.\\)\n4. Remove diagnostic logs once working\n\nCo-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(git fetch:*)",
      "Bash(git pull:*)",
      "mcp__supabase__list_tables",
      "Bash(find:*)",
      "mcp__supabase__apply_migration",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nfeat: implement dual QA learning systems with progressive strength and health decay\n\nImplemented two complementary QA learning systems that enable the AI to learn\nfrom mistakes while preventing over-restriction.\n\n## System 1: Constraint Escalation \\(Prompt Engineering\\)\n- Rules escalate through priority levels based on violation frequency:\n  * Body \\(default\\) → Critical \\(2+ violations\\) → System \\(4+ violations\\)\n- Higher-level constraints get prioritized in prompts for better AI attention\n- Includes constraint stack depth visibility \\(\"Base + N learned constraints\"\\)\n- Promotion audit log tracks when rules activate and escalate\n- Retry analytics dashboard visualizes learning effectiveness over time\n\n## System 2: Progressive Learning \\(User Experience\\)\n- Three-tier learning: Pipeline \\(temporary\\) → User \\(personal\\) → Global \\(system-wide\\)\n- Progressive rule strength that starts weak and only strengthens with proof:\n  * Nudge \\(hint, no blocking\\) → Check \\(requires confirmation\\) → \n    Guard \\(soft block with reason\\) → Law \\(hard block\\)\n- Health bar decay system naturally removes stale rules:\n  * Time decay: -2 health/day\n  * Good behavior decay: -5 when user succeeds without triggering\n  * False positive decay: -30 when rule is wrong\n- Confidence scoring prevents inconsistent rules from blocking \\(< 70% stays at nudge\\)\n- User dashboard with mute/lock/delete/reset controls\n\n## Database Changes\nNew tables:\n- qa_pipeline_instance_rules: Temporary pipeline-level rules\n- qa_rule_promotion_log: Audit log of promotions/escalations\n- qa_rule_overrides: Tracks user override decisions\n- qa_user_learning_profile: Per-user learning preferences\n\nExtended qa_policy_rules with 13 new columns:\n- violation_count, escalation_level \\(System 1\\)\n- strength_stage, health, confidence_score \\(System 2\\)\n- context_conditions, triggered_count, user_muted, user_locked, etc.\n\n## Edge Functions \\(4 new\\)\n- get-constraint-stack-depth: Returns active constraint counts by level\n- get-rule-promotion-log: Query promotion history\n- get-retry-analytics: Visualize retry trends over time\n- reset-learning-profile: Fresh start for users\n\n## Frontend Components \\(5 new/modified\\)\n- QALearningDashboard: Full rule management interface\n- QAProgressiveWarning: In-flow progressive warnings \\(nudge/check/guard/law\\)\n- RetryAnalyticsDashboard: Retry trend visualization with 7/30/90 day views\n- PipelineDebugPanel: Extended with constraint stack depth display\n- useConstraintStackDepth: React hook for fetching constraint data\n\n## Integration Points\n- run-qa-check: Tracks violations and updates escalation levels\n- store-qa-feedback: Logs rule activations and updates confidence scores\n\n## Key Benefits\n- Rules start weak \\(hints\\) and only strengthen with repeated violations\n- Unused rules naturally decay and disappear \\(health system\\)\n- Bad rules die quickly from false positive penalty\n- Low-confidence rules never become blocking\n- Users maintain full control with dashboard and overrides\n- Retry count trends toward 0 as AI learns\n\nTesting: Complete testing checklist in docs/EXECUTION_SUMMARY.md\n\nFiles: 20 files created/modified across migrations, backend, frontend, and docs\n\nCo-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(git push:*)",
      "Bash(supabase --version:*)",
      "Bash(supabase status:*)",
      "Bash(supabase link:*)",
      "mcp__supabase__get_project_url",
      "mcp__supabase__list_migrations",
      "Bash(ls:*)",
      "Bash(supabase db push:*)",
      "Bash(supabase projects list:*)",
      "Bash(supabase db pull:*)",
      "Bash(supabase migration repair:*)",
      "Bash(supabase migration:*)",
      "Bash(supabase functions deploy:*)",
      "Bash(git commit:*)",
      "Bash(supabase functions list:*)",
      "Bash(supabase db dump:*)"
    ]
  },
  "enableAllProjectMcpServers": true,
  "enabledMcpjsonServers": [
    "supabase"
  ]
}
